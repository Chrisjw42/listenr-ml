{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import librosa\n",
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import sklearn\n",
    "import dask.dataframe as dd\n",
    "from dask import array\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import librosa.display\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv1D, Dropout, Dense, MaxPooling1D, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import Sequential\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client, wait, progress\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dd.read_parquet(\"res/*.parquet\").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model params (2D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = load_model(\"md/0.1-2-64-128-False.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>n_conv</th>\n",
       "      <th>base_dense</th>\n",
       "      <th>n_filters</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.169319</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  n_conv  base_dense  n_filters      loss  acc\n",
       "5      0.1     2.0        64.0      128.0  0.169319  0.1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"res/0.1-2-64-128-False.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best 1D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stft_2d(y, sr = 22050, hop_length=32):\n",
    "    D = librosa.stft(y, hop_length=hop_length, n_fft=1024)\n",
    "    spec = librosa.amplitude_to_db(D,ref=np.max)\n",
    "    df = pd.DataFrame(spec / 80)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_in_seconds(y,sr):\n",
    "    return len(y)/sr\n",
    "\n",
    "def create_samples_from_fn(fn, desired_sr = 22050):\n",
    "    \"\"\"\n",
    "    Also trims silence from a file\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        # Load, resample if needed\n",
    "        y, sr = librosa.load(fn)\n",
    "    except:\n",
    "        return None\n",
    "    if sr != desired_sr:\n",
    "        y = librosa.core.resample(y, sr, desired_sr)\n",
    "        sr = desired_sr\n",
    "\n",
    "    # Standard scaling\n",
    "    standardScaler = StandardScaler()    \n",
    "    y = standardScaler.fit_transform(y.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    length = get_length_in_seconds(y, sr)\n",
    "\n",
    "    # Trim silence\n",
    "    y_trimmed = librosa.effects.trim(y, top_db=12.5)[0]\n",
    "    length_trimmed = get_length_in_seconds(y_trimmed, sr)\n",
    "\n",
    "    # Split into chunks\n",
    "    chunk_len = int(sr / 2) # .5 seconds\n",
    "    end = len(y_trimmed) - (len(y_trimmed) % chunk_len)\n",
    "    n_chunks = int(end / chunk_len)\n",
    "    if n_chunks == 0:\n",
    "        return None\n",
    "    y_trimmed_chunks = np.split(y_trimmed[:end], n_chunks)\n",
    "    y_trimmed_chunks = [x for x in y_trimmed_chunks]\n",
    "    \n",
    "    return y_trimmed_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_features(y,sr = 22050, hop_length=32):\n",
    "    n_cont_bands = 2\n",
    "    res = pd.DataFrame(columns=[\"contrast_band_{}\".format(x) for x in range(n_cont_bands+1)].extend([\"sroll\", \"sflat\"]))\n",
    "    \n",
    "    scont = librosa.feature.spectral_contrast(y,n_bands=n_cont_bands, hop_length=hop_length)\n",
    "    \n",
    "    for i in range(n_cont_bands + 1):\n",
    "        res[\"contrast_band_{}\".format(i)] = scont[i]\n",
    "        \n",
    "    sroll = librosa.feature.spectral_rolloff(y,sr, hop_length=hop_length)[0].T\n",
    "    res[\"sroll\"] = sroll\n",
    "    \n",
    "    sflat = librosa.feature.spectral_flatness(y, hop_length=hop_length)[0].T\n",
    "    res[\"sflat\"] = sflat\n",
    "    \n",
    "    y_df = pd.DataFrame(y)\n",
    "    res[\"downsampled\"] = y_df.groupby(y_df.index//hop_length).mean().rolling(2).mean()\n",
    "    res[\"downsampled_smooth_abs\"] = y_df.abs().groupby(y_df.index//hop_length).mean().rolling(6).mean()\n",
    "\n",
    "    return res.fillna(method=\"backfill\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.3588106 , -0.00266513,  0.44744202, ..., -0.37154463,\n",
      "       -0.49179968, -0.34090018], dtype=float32), array([-0.02592736,  0.06822344, -0.03271784, ..., -0.9426107 ,\n",
      "       -0.9915499 , -1.0199014 ], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\librosa\\core\\spectrum.py:960: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  warnings.warn('amplitude_to_db was called on complex input so phase '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-54.67341 , -54.690697, -54.840923, ..., -35.32738 , -34.876953,\n",
      "        -34.654335],\n",
      "       [-57.42822 , -57.548817, -57.774273, ..., -35.23271 , -35.01561 ,\n",
      "        -34.909195],\n",
      "       [-55.891888, -55.953175, -56.233017, ..., -36.299625, -35.831867,\n",
      "        -35.59884 ],\n",
      "       ...,\n",
      "       [-76.11128 , -76.197815, -76.4498  , ..., -80.      , -80.      ,\n",
      "        -80.      ],\n",
      "       [-76.38053 , -76.46394 , -76.727394, ..., -80.      , -80.      ,\n",
      "        -80.      ],\n",
      "       [-76.38255 , -76.4669  , -76.70944 , ..., -80.      , -80.      ,\n",
      "        -80.      ]], dtype=float32), array([[-32.049377, -32.097584, -32.351387, ..., -37.92804 , -37.538555,\n",
      "        -37.572678],\n",
      "       [-32.571735, -32.687756, -32.92295 , ..., -37.288055, -36.94465 ,\n",
      "        -36.576015],\n",
      "       [-35.860558, -35.850716, -35.98919 , ..., -34.803413, -34.509445,\n",
      "        -34.501366],\n",
      "       ...,\n",
      "       [-67.725845, -67.8069  , -68.056656, ..., -80.      , -80.      ,\n",
      "        -80.      ],\n",
      "       [-67.783485, -67.87017 , -68.12702 , ..., -80.      , -80.      ,\n",
      "        -80.      ],\n",
      "       [-67.811554, -67.89284 , -68.14314 , ..., -80.      , -80.      ,\n",
      "        -80.      ]], dtype=float32)]\n",
      "[array([[ 1.59321742e+01,  2.32568562e+01,  3.06110033e+01, ...,\n",
      "         3.66110317e-02,  1.49898476e-02,  2.34516228e-01],\n",
      "       [ 1.58646760e+01,  2.21213979e+01,  2.69446296e+01, ...,\n",
      "         4.15643714e-02,  1.49898476e-02,  2.34516228e-01],\n",
      "       [ 1.52803738e+01,  2.04467226e+01,  2.59467155e+01, ...,\n",
      "         4.33571264e-02,  9.65181645e-03,  2.34516228e-01],\n",
      "       ...,\n",
      "       [ 5.18849601e+00,  7.89624660e+00,  3.56525580e+01, ...,\n",
      "         8.57670084e-02,  4.91999462e-03,  3.46141681e-01],\n",
      "       [ 5.35119741e+00,  9.67756303e+00,  3.58250904e+01, ...,\n",
      "         7.63339326e-02,  3.07070762e-02,  3.67430950e-01],\n",
      "       [ 5.43832332e+00,  1.19333566e+01,  3.63732232e+01, ...,\n",
      "         6.66663796e-02, -2.42131311e-01,  3.88036549e-01]]), array([[ 7.74852093e+00,  1.73336124e+01,  3.00190218e+01, ...,\n",
      "         2.92410366e-02,  1.94489047e-01,  6.07868860e-01],\n",
      "       [ 7.80914800e+00,  1.74669313e+01,  2.80617820e+01, ...,\n",
      "         3.16657647e-02,  1.94489047e-01,  6.07868860e-01],\n",
      "       [ 7.88410300e+00,  1.78054614e+01,  2.72097478e+01, ...,\n",
      "         3.39078680e-02, -1.55312940e-01,  6.07868860e-01],\n",
      "       ...,\n",
      "       [ 5.08888604e+00,  1.90530337e+01,  4.10528084e+01, ...,\n",
      "         7.08010630e-04, -1.38882548e-02,  1.33951620e+00],\n",
      "       [ 4.84357181e+00,  1.99955631e+01,  4.20275355e+01, ...,\n",
      "         6.43961597e-04,  2.50196710e-01,  1.29908541e+00],\n",
      "       [ 4.72859533e+00,  2.06121101e+01,  4.40742883e+01, ...,\n",
      "         5.79694635e-04, -3.66921797e-02,  1.01301006e+00]])]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sample(fn):\n",
    "    # Load\n",
    "    chunks = create_samples_from_fn(fn)\n",
    "    # Break into chunks\n",
    "    print(chunks)\n",
    "    \n",
    "    # 2D transformation\n",
    "    chunks_2d = [get_stft_2d(ch) for ch in chunks]\n",
    "    \n",
    "    # 1D transformation\n",
    "    chunks_1d = [get_ts_features(ch).values for ch in chunks] \n",
    "    print(chunks_2d)\n",
    "    print(chunks_1d)\n",
    "    return chunks_1d, chunks_2d \n",
    "    \n",
    "one, two = preprocess_sample(\"../data/listenr-ml/RAVDESS-Audio_Speech_Actors_01-24/Actor_02/03-01-01-01-01-01-02.wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_2d = load_model(\"md/0.1-2-64-128-False.md\")\n",
    "md_1d = load_model(\"md/1d.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 345)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ab3b23b9c727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmd_2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m513\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m345\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]"
     ]
    }
   ],
   "source": [
    "md_2d.predict(two[0].reshape(-1, 513, 345, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
